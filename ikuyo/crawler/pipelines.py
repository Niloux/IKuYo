#!/usr/bin/env python3
"""
æ•°æ®å¤„ç†ç®¡é“
è´Ÿè´£å°†çˆ¬å–çš„æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“
æ›´æ–°ä»¥æ”¯æŒè¯»å†™åˆ†ç¦»æ¶æ„
"""


from scrapy.exceptions import DropItem

from ..core.database import DatabaseManager
from .items import AnimeItem, AnimeSubtitleGroupItem, CrawlLogItem, ResourceItem, SubtitleGroupItem


class ValidationPipeline:
    """æ•°æ®éªŒè¯Pipeline"""

    def process_item(self, item, spider):
        if isinstance(item, AnimeItem):
            if not item.get("mikan_id") or not item.get("title"):
                raise DropItem(f"Missing required fields in AnimeItem: {item}")
        elif isinstance(item, ResourceItem):
            if not item.get("mikan_id") or not item.get("subtitle_group_id"):
                raise DropItem(f"Missing required fields in ResourceItem: {item}")
        elif isinstance(item, SubtitleGroupItem):
            if not item.get("id") or not item.get("name"):
                raise DropItem(f"Missing required fields in SubtitleGroupItem: {item}")
        elif isinstance(item, AnimeSubtitleGroupItem):
            if not item.get("mikan_id") or not item.get("subtitle_group_id"):
                raise DropItem(f"Missing required fields in AnimeSubtitleGroupItem: {item}")

        return item


class SQLitePipeline:
    """SQLiteæ•°æ®åº“Pipeline - ä½¿ç”¨è¯»å†™åˆ†ç¦»æ¶æ„"""

    def __init__(self):
        self.db_manager = None

    def open_spider(self, spider):
        """åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨"""
        try:
            self.db_manager = DatabaseManager()
            spider.logger.info("âœ… æ•°æ®åº“ç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼ˆè¯»å†™åˆ†ç¦»æ¨¡å¼ï¼‰")

        except Exception as e:
            spider.logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise e

    def close_spider(self, spider):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.db_manager:
            try:
                self.db_manager.close_all()
                spider.logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
            except Exception as e:
                spider.logger.error(f"å…³é—­æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")

    def process_item(self, item, spider):
        """å¤„ç†æ•°æ®é¡¹ - ä½¿ç”¨å†™è¿æ¥"""
        if not self.db_manager:
            return item

        try:
            if isinstance(item, AnimeItem):
                self.save_anime(item)
            elif isinstance(item, SubtitleGroupItem):
                self.save_subtitle_group(item)
            elif isinstance(item, AnimeSubtitleGroupItem):
                self.save_anime_subtitle_group(item)
            elif isinstance(item, ResourceItem):
                self.save_resource(item)
            elif isinstance(item, CrawlLogItem):
                self.save_crawl_log(item)
        except Exception as e:
            spider.logger.error(f"Error saving item to database: {e}")
            raise DropItem(f"Database error: {e}")

        return item

    def save_anime(self, item):
        """ä¿å­˜åŠ¨ç”»ä¿¡æ¯ - ä½¿ç”¨å†™è¿æ¥"""
        if not self.db_manager:
            return

        query = """
        INSERT OR REPLACE INTO animes 
        (mikan_id, bangumi_id, title, original_title, broadcast_day, broadcast_start,
         official_website, bangumi_url, description, status, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        params = (
            item.get("mikan_id"),
            item.get("bangumi_id"),
            item.get("title"),
            item.get("original_title"),
            item.get("broadcast_day"),
            item.get("broadcast_start"),
            item.get("official_website"),
            item.get("bangumi_url"),
            item.get("description"),
            item.get("status", "unknown"),
            item.get("created_at"),
            item.get("updated_at"),
        )

        self.db_manager.execute_update(query, params)

    def save_subtitle_group(self, item):
        """ä¿å­˜å­—å¹•ç»„ä¿¡æ¯ - ä½¿ç”¨å†™è¿æ¥"""
        if not self.db_manager:
            return

        query = """
        INSERT OR REPLACE INTO subtitle_groups 
        (id, name, last_update, created_at)
        VALUES (?, ?, ?, ?)
        """
        params = (
            item.get("id"),
            item.get("name"),
            item.get("last_update"),
            item.get("created_at"),
        )

        self.db_manager.execute_update(query, params)

    def save_anime_subtitle_group(self, item):
        """ä¿å­˜åŠ¨ç”»-å­—å¹•ç»„å…³è”ä¿¡æ¯ - ä½¿ç”¨å†™è¿æ¥"""
        if not self.db_manager:
            return

        query = """
        INSERT OR REPLACE INTO anime_subtitle_groups 
        (mikan_id, subtitle_group_id, first_release_date, last_update_date,
         resource_count, is_active, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """
        params = (
            item.get("mikan_id"),
            item.get("subtitle_group_id"),
            item.get("first_release_date"),
            item.get("last_update_date"),
            item.get("resource_count", 0),
            item.get("is_active", 1),
            item.get("created_at"),
            item.get("updated_at"),
        )

        self.db_manager.execute_update(query, params)

    def save_resource(self, item):
        """ä¿å­˜èµ„æºä¿¡æ¯ - ä½¿ç”¨å†™è¿æ¥"""
        if not self.db_manager:
            return

        query = """
        INSERT OR REPLACE INTO resources 
        (mikan_id, subtitle_group_id, episode_number, title, file_size,
         resolution, subtitle_type, magnet_url, torrent_url, play_url,
         magnet_hash, release_date, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        params = (
            item.get("mikan_id"),
            item.get("subtitle_group_id"),
            item.get("episode_number"),
            item.get("title"),
            item.get("file_size"),
            item.get("resolution"),
            item.get("subtitle_type"),
            item.get("magnet_url"),
            item.get("torrent_url"),
            item.get("play_url"),
            item.get("magnet_hash"),
            item.get("release_date"),
            item.get("created_at"),
            item.get("updated_at"),
        )

        self.db_manager.execute_update(query, params)

    def save_crawl_log(self, item):
        """ä¿å­˜çˆ¬å–æ—¥å¿— - ä½¿ç”¨å†™è¿æ¥"""
        if not self.db_manager:
            return

        query = """
        INSERT INTO crawl_logs 
        (spider_name, start_time, end_time, status, items_count, mikan_id,
         error_message, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """
        params = (
            item.get("spider_name"),
            item.get("start_time"),
            item.get("end_time"),
            item.get("status"),
            item.get("items_count", 0),
            item.get("mikan_id"),
            item.get("error_message"),
            item.get("created_at"),
        )

        self.db_manager.execute_update(query, params)


class DuplicatesPipeline:
    """å»é‡Pipeline - é€‚é…æ–°ç»“æ„"""

    def __init__(self):
        self.anime_ids = set()
        self.subtitle_group_ids = set()
        self.resource_hashes = set()
        self.anime_subtitle_group_pairs = set()

    def process_item(self, item, spider):
        if isinstance(item, AnimeItem):
            mikan_id = item.get("mikan_id")
            if mikan_id in self.anime_ids:
                raise DropItem(f"Duplicate anime: {mikan_id}")
            self.anime_ids.add(mikan_id)

        elif isinstance(item, SubtitleGroupItem):
            group_id = item.get("id")
            if group_id in self.subtitle_group_ids:
                raise DropItem(f"Duplicate subtitle group: {group_id}")
            self.subtitle_group_ids.add(group_id)

        elif isinstance(item, AnimeSubtitleGroupItem):
            mikan_id = item.get("mikan_id")
            subtitle_group_id = item.get("subtitle_group_id")
            pair = (mikan_id, subtitle_group_id)
            if pair in self.anime_subtitle_group_pairs:
                raise DropItem(f"Duplicate anime-subtitle group pair: {pair}")
            self.anime_subtitle_group_pairs.add(pair)

        elif isinstance(item, ResourceItem):
            magnet_hash = item.get("magnet_hash")
            if magnet_hash and magnet_hash in self.resource_hashes:
                raise DropItem(f"Duplicate resource: {magnet_hash}")
            if magnet_hash:
                self.resource_hashes.add(magnet_hash)

        return item


class BatchSQLitePipeline:
    """æ‰¹é‡å­˜å‚¨Pipeline - å‡å°‘æ•°æ®åº“å†™æ“ä½œæ¬¡æ•°"""

    def __init__(self):
        self.db_manager = None
        self.batch_size = 100  # ç®€å•å›ºå®šå€¼ï¼Œä¸æå¤æ‚é…ç½®

        # åˆ†ç±»ç¼“å­˜ä¸åŒç±»å‹çš„items
        self.batches = {
            "animes": [],
            "subtitle_groups": [],
            "anime_subtitle_groups": [],
            "resources": [],
            "crawl_logs": [],
        }

    def open_spider(self, spider):
        """åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨"""
        try:
            self.db_manager = DatabaseManager()
            spider.logger.info("âœ… æ‰¹é‡å­˜å‚¨Pipelineå·²åˆå§‹åŒ–")

        except Exception as e:
            spider.logger.error(f"æ‰¹é‡Pipelineåˆå§‹åŒ–å¤±è´¥: {e}")
            raise e

    def close_spider(self, spider):
        """çˆ¬è™«ç»“æŸæ—¶åˆ·æ–°æ‰€æœ‰ç¼“å­˜"""
        if self.db_manager:
            try:
                # åˆ·æ–°æ‰€æœ‰ç¼“å­˜çš„æ•°æ®
                self._flush_all_batches(spider)
                self.db_manager.close_all()
                spider.logger.info("âœ… æ‰¹é‡å­˜å‚¨Pipelineå·²å…³é—­")
            except Exception as e:
                spider.logger.error(f"å…³é—­æ‰¹é‡Pipelineå¤±è´¥: {e}")

    def process_item(self, item, spider):
        """ç¼“å­˜itemï¼Œè¾¾åˆ°é˜ˆå€¼æ—¶æ‰¹é‡å†™å…¥"""
        if not self.db_manager:
            return item

        try:
            # æ ¹æ®itemç±»å‹ç¼“å­˜åˆ°å¯¹åº”çš„æ‰¹æ¬¡ä¸­
            if isinstance(item, AnimeItem):
                self.batches["animes"].append(item)
                if len(self.batches["animes"]) >= self.batch_size:
                    self._flush_animes(spider)

            elif isinstance(item, SubtitleGroupItem):
                self.batches["subtitle_groups"].append(item)
                if len(self.batches["subtitle_groups"]) >= self.batch_size:
                    self._flush_subtitle_groups(spider)

            elif isinstance(item, AnimeSubtitleGroupItem):
                self.batches["anime_subtitle_groups"].append(item)
                if len(self.batches["anime_subtitle_groups"]) >= self.batch_size:
                    # å…ˆåˆ·æ–°ä¾èµ–é¡¹ï¼Œå†åˆ·æ–°å½“å‰é¡¹
                    self._flush_dependencies_first(spider)
                    self._flush_anime_subtitle_groups(spider)

            elif isinstance(item, ResourceItem):
                self.batches["resources"].append(item)
                if len(self.batches["resources"]) >= self.batch_size:
                    # å…ˆåˆ·æ–°ä¾èµ–é¡¹ï¼Œå†åˆ·æ–°å½“å‰é¡¹
                    self._flush_dependencies_first(spider)
                    self._flush_resources(spider)

            elif isinstance(item, CrawlLogItem):
                self.batches["crawl_logs"].append(item)
                if len(self.batches["crawl_logs"]) >= self.batch_size:
                    self._flush_crawl_logs(spider)

        except Exception as e:
            spider.logger.error(f"æ‰¹é‡å¤„ç†itemå¤±è´¥: {e}")
            raise DropItem(f"Batch processing error: {e}")

        return item

    def _flush_dependencies_first(self, spider):
        """ä¼˜å…ˆåˆ·æ–°ä¾èµ–é¡¹ï¼ˆanimeså’Œsubtitle_groupsï¼‰"""
        if self.batches["animes"]:
            self._flush_animes(spider)
        if self.batches["subtitle_groups"]:
            self._flush_subtitle_groups(spider)

    def _flush_animes(self, spider):
        """æ‰¹é‡æ’å…¥åŠ¨ç”»æ•°æ®"""
        if not self.batches["animes"]:
            return

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œwrite_managerå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "write_manager"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        try:
            with self.db_manager.write_manager.get_write_connection() as conn:
                cursor = conn.cursor()

                data = []
                for item in self.batches["animes"]:
                    data.append((
                        item.get("mikan_id"),
                        item.get("bangumi_id"),
                        item.get("title"),
                        item.get("original_title"),
                        item.get("broadcast_day"),
                        item.get("broadcast_start"),
                        item.get("official_website"),
                        item.get("bangumi_url"),
                        item.get("description"),
                        item.get("status", "unknown"),
                        item.get("created_at"),
                        item.get("updated_at"),
                    ))

                cursor.executemany(
                    """
                    INSERT OR REPLACE INTO animes 
                    (mikan_id, bangumi_id, title, original_title, broadcast_day, broadcast_start,
                     official_website, bangumi_url, description, status, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    data,
                )

                conn.commit()
                spider.logger.info(f"âœ… æ‰¹é‡æ’å…¥åŠ¨ç”»: {len(data)} æ¡")

        except Exception as e:
            spider.logger.error(f"æ‰¹é‡æ’å…¥åŠ¨ç”»å¤±è´¥: {e}")
            # é™çº§ä¸ºå•æ¡æ’å…¥
            self._fallback_insert_animes(spider)

        finally:
            self.batches["animes"].clear()

    def _flush_subtitle_groups(self, spider):
        """æ‰¹é‡æ’å…¥å­—å¹•ç»„æ•°æ®"""
        if not self.batches["subtitle_groups"]:
            return

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œwrite_managerå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "write_manager"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        try:
            with self.db_manager.write_manager.get_write_connection() as conn:
                cursor = conn.cursor()

                data = []
                for item in self.batches["subtitle_groups"]:
                    data.append((
                        item.get("id"),
                        item.get("name"),
                        item.get("last_update"),
                        item.get("created_at"),
                    ))

                cursor.executemany(
                    """
                    INSERT OR REPLACE INTO subtitle_groups 
                    (id, name, last_update, created_at)
                    VALUES (?, ?, ?, ?)
                """,
                    data,
                )

                conn.commit()
                spider.logger.info(f"âœ… æ‰¹é‡æ’å…¥å­—å¹•ç»„: {len(data)} æ¡")

        except Exception as e:
            spider.logger.error(f"æ‰¹é‡æ’å…¥å­—å¹•ç»„å¤±è´¥: {e}")
            self._fallback_insert_subtitle_groups(spider)

        finally:
            self.batches["subtitle_groups"].clear()

    def _flush_anime_subtitle_groups(self, spider):
        """æ‰¹é‡æ’å…¥åŠ¨ç”»-å­—å¹•ç»„å…³è”æ•°æ®"""
        if not self.batches["anime_subtitle_groups"]:
            return

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œwrite_managerå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "write_manager"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        try:
            with self.db_manager.write_manager.get_write_connection() as conn:
                cursor = conn.cursor()

                data = []
                for item in self.batches["anime_subtitle_groups"]:
                    data.append((
                        item.get("mikan_id"),
                        item.get("subtitle_group_id"),
                        item.get("first_release_date"),
                        item.get("last_update_date"),
                        item.get("resource_count", 0),
                        item.get("is_active", 1),
                        item.get("created_at"),
                        item.get("updated_at"),
                    ))

                cursor.executemany(
                    """
                    INSERT OR REPLACE INTO anime_subtitle_groups 
                    (mikan_id, subtitle_group_id, first_release_date, last_update_date,
                     resource_count, is_active, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    data,
                )

                conn.commit()
                spider.logger.info(f"âœ… æ‰¹é‡æ’å…¥åŠ¨ç”»-å­—å¹•ç»„å…³è”: {len(data)} æ¡")

        except Exception as e:
            spider.logger.error(f"æ‰¹é‡æ’å…¥å…³è”æ•°æ®å¤±è´¥: {e}")
            # é™çº§å‰å…ˆç¡®ä¿ä¾èµ–é¡¹å­˜åœ¨
            self._ensure_dependencies_exist(spider)
            self._fallback_insert_anime_subtitle_groups(spider)

        finally:
            self.batches["anime_subtitle_groups"].clear()

    def _flush_resources(self, spider):
        """æ‰¹é‡æ’å…¥èµ„æºæ•°æ®"""
        if not self.batches["resources"]:
            return

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œwrite_managerå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "write_manager"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        try:
            with self.db_manager.write_manager.get_write_connection() as conn:
                cursor = conn.cursor()

                data = []
                for item in self.batches["resources"]:
                    data.append((
                        item.get("mikan_id"),
                        item.get("subtitle_group_id"),
                        item.get("episode_number"),
                        item.get("title"),
                        item.get("file_size"),
                        item.get("resolution"),
                        item.get("subtitle_type"),
                        item.get("magnet_url"),
                        item.get("torrent_url"),
                        item.get("play_url"),
                        item.get("magnet_hash"),
                        item.get("release_date"),
                        item.get("created_at"),
                        item.get("updated_at"),
                    ))

                cursor.executemany(
                    """
                    INSERT OR REPLACE INTO resources 
                    (mikan_id, subtitle_group_id, episode_number, title, file_size,
                     resolution, subtitle_type, magnet_url, torrent_url, play_url,
                     magnet_hash, release_date, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    data,
                )

                conn.commit()
                spider.logger.info(f"âœ… æ‰¹é‡æ’å…¥èµ„æº: {len(data)} æ¡")

        except Exception as e:
            spider.logger.error(f"æ‰¹é‡æ’å…¥èµ„æºå¤±è´¥: {e}")
            # é™çº§å‰å…ˆç¡®ä¿ä¾èµ–é¡¹å­˜åœ¨
            self._ensure_dependencies_exist(spider)
            self._fallback_insert_resources(spider)

        finally:
            self.batches["resources"].clear()

    def _flush_crawl_logs(self, spider):
        """æ‰¹é‡æ’å…¥çˆ¬å–æ—¥å¿—"""
        if not self.batches["crawl_logs"]:
            return

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œwrite_managerå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "write_manager"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        try:
            with self.db_manager.write_manager.get_write_connection() as conn:
                cursor = conn.cursor()

                data = []
                for item in self.batches["crawl_logs"]:
                    data.append((
                        item.get("spider_name"),
                        item.get("start_time"),
                        item.get("end_time"),
                        item.get("status"),
                        item.get("items_count", 0),
                        item.get("mikan_id"),
                        item.get("error_message"),
                        item.get("created_at"),
                    ))

                cursor.executemany(
                    """
                    INSERT INTO crawl_logs 
                    (spider_name, start_time, end_time, status, items_count, mikan_id,
                     error_message, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    data,
                )

                conn.commit()
                spider.logger.info(f"âœ… æ‰¹é‡æ’å…¥æ—¥å¿—: {len(data)} æ¡")

        except Exception as e:
            spider.logger.error(f"æ‰¹é‡æ’å…¥æ—¥å¿—å¤±è´¥: {e}")

        finally:
            self.batches["crawl_logs"].clear()

    def _flush_all_batches(self, spider):
        """åˆ·æ–°æ‰€æœ‰ç¼“å­˜çš„æ‰¹æ¬¡"""
        spider.logger.info("ğŸ”„ åˆ·æ–°æ‰€æœ‰ç¼“å­˜æ‰¹æ¬¡...")

        self._flush_animes(spider)
        self._flush_subtitle_groups(spider)
        self._flush_anime_subtitle_groups(spider)
        self._flush_resources(spider)
        self._flush_crawl_logs(spider)

        spider.logger.info("âœ… æ‰€æœ‰æ‰¹æ¬¡åˆ·æ–°å®Œæˆ")

    def _fallback_insert_animes(self, spider):
        """é™çº§ä¸ºå•æ¡æ’å…¥åŠ¨ç”»ï¼ˆå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        spider.logger.warning("ğŸ”„ é™çº§ä¸ºå•æ¡æ’å…¥åŠ¨ç”»...")

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œexecute_updateå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "execute_update"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        for item in self.batches["animes"]:
            try:
                self.db_manager.execute_update(
                    """
                    INSERT OR REPLACE INTO animes 
                    (mikan_id, bangumi_id, title, original_title, broadcast_day, broadcast_start,
                     official_website, bangumi_url, description, status, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        item.get("mikan_id"),
                        item.get("bangumi_id"),
                        item.get("title"),
                        item.get("original_title"),
                        item.get("broadcast_day"),
                        item.get("broadcast_start"),
                        item.get("official_website"),
                        item.get("bangumi_url"),
                        item.get("description"),
                        item.get("status", "unknown"),
                        item.get("created_at"),
                        item.get("updated_at"),
                    ),
                )
            except Exception as e:
                spider.logger.error(f"å•æ¡æ’å…¥åŠ¨ç”»å¤±è´¥: {e}")

    def _fallback_insert_subtitle_groups(self, spider):
        """é™çº§ä¸ºå•æ¡æ’å…¥å­—å¹•ç»„ï¼ˆå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        spider.logger.warning("ğŸ”„ é™çº§ä¸ºå•æ¡æ’å…¥å­—å¹•ç»„...")

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œexecute_updateå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "execute_update"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        for item in self.batches["subtitle_groups"]:
            try:
                self.db_manager.execute_update(
                    """
                    INSERT OR REPLACE INTO subtitle_groups 
                    (id, name, last_update, created_at)
                    VALUES (?, ?, ?, ?)
                """,
                    (
                        item.get("id"),
                        item.get("name"),
                        item.get("last_update"),
                        item.get("created_at"),
                    ),
                )
            except Exception as e:
                spider.logger.error(f"å•æ¡æ’å…¥å­—å¹•ç»„å¤±è´¥: {e}")

    def _fallback_insert_anime_subtitle_groups(self, spider):
        """é™çº§ä¸ºå•æ¡æ’å…¥å…³è”æ•°æ®ï¼ˆå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        spider.logger.warning("ğŸ”„ é™çº§ä¸ºå•æ¡æ’å…¥å…³è”æ•°æ®...")

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œexecute_updateå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "execute_update"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        for item in self.batches["anime_subtitle_groups"]:
            try:
                self.db_manager.execute_update(
                    """
                    INSERT OR REPLACE INTO anime_subtitle_groups 
                    (mikan_id, subtitle_group_id, first_release_date, last_update_date,
                     resource_count, is_active, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        item.get("mikan_id"),
                        item.get("subtitle_group_id"),
                        item.get("first_release_date"),
                        item.get("last_update_date"),
                        item.get("resource_count", 0),
                        item.get("is_active", 1),
                        item.get("created_at"),
                        item.get("updated_at"),
                    ),
                )
            except Exception as e:
                spider.logger.error(f"å•æ¡æ’å…¥å…³è”æ•°æ®å¤±è´¥: {e}")

    def _fallback_insert_resources(self, spider):
        """é™çº§ä¸ºå•æ¡æ’å…¥èµ„æºï¼ˆå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        spider.logger.warning("ğŸ”„ é™çº§ä¸ºå•æ¡æ’å…¥èµ„æº...")

        # ç±»å‹æ£€æŸ¥ - ç¡®ä¿db_managerå’Œexecute_updateå­˜åœ¨
        if not self.db_manager or not hasattr(self.db_manager, "execute_update"):
            spider.logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            return

        for item in self.batches["resources"]:
            try:
                self.db_manager.execute_update(
                    """
                    INSERT OR REPLACE INTO resources 
                    (mikan_id, subtitle_group_id, episode_number, title, file_size,
                     resolution, subtitle_type, magnet_url, torrent_url, play_url,
                     magnet_hash, release_date, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        item.get("mikan_id"),
                        item.get("subtitle_group_id"),
                        item.get("episode_number"),
                        item.get("title"),
                        item.get("file_size"),
                        item.get("resolution"),
                        item.get("subtitle_type"),
                        item.get("magnet_url"),
                        item.get("torrent_url"),
                        item.get("play_url"),
                        item.get("magnet_hash"),
                        item.get("release_date"),
                        item.get("created_at"),
                        item.get("updated_at"),
                    ),
                )
            except Exception as e:
                spider.logger.error(f"å•æ¡æ’å…¥èµ„æºå¤±è´¥: {e}")

    def _ensure_dependencies_exist(self, spider):
        """ç¡®ä¿ä¾èµ–é¡¹å­˜åœ¨ï¼Œç”¨äºé™çº§å¤„ç†å‰"""
        spider.logger.info("ğŸ”„ ç¡®ä¿ä¾èµ–é¡¹å­˜åœ¨...")

        # å…ˆå¤„ç†æ‰€æœ‰å¾…å¤„ç†çš„animeså’Œsubtitle_groups
        if self.batches["animes"]:
            spider.logger.info(f"å…ˆæ’å…¥å¾…å¤„ç†çš„åŠ¨ç”»: {len(self.batches['animes'])} æ¡")
            self._flush_animes(spider)

        if self.batches["subtitle_groups"]:
            spider.logger.info(f"å…ˆæ’å…¥å¾…å¤„ç†çš„å­—å¹•ç»„: {len(self.batches['subtitle_groups'])} æ¡")
            self._flush_subtitle_groups(spider)
